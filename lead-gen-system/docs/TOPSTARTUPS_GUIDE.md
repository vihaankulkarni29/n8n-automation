# ðŸš€ Top Startups India Scraper - User Guide

## Why This Scraper is GOLD for Your Submission ðŸ’Ž

**Top Startups India** gives you access to:
- âœ… **Funded startups** ($1M to $500M+ funding!)
- âœ… **Job listings** (companies hiring = hot leads!)
- âœ… **Verified data** (curated startup database)
- âœ… **Rich profiles** (employees, industry, founded year)
- âœ… **FREE** (no API key needed!)

**Perfect for**: Lead gen submissions showing you can target HIGH-VALUE clients!

---

## ðŸ“‹ Quick Start (2 Minutes)

### Run the Scraper:

```powershell
cd "c:\Users\Vihaan\Desktop\references\n8n automation\lead-gen-system"
python scrapers/topstartups_scraper.py
```

**Expected output**:
```
Starting Top Startups India scraper...
Chrome WebDriver initialized successfully
Loading page: https://topstartups.io/?hq_location=India
Scrolling page 8 times to load all content...
Found 127 company blocks using selector: div[class*="company"]
Processing 127 company blocks...
Extracted company 1: Razorpay
Extracted company 2: CRED
...
Successfully scraped 120 companies

TOP STARTUPS INDIA - SCRAPING STATISTICS
========================================
Total Companies Scraped: 120
With Website: 98 (81.7%)
With Funding Info: 87 (72.5%)
With Job Listings: 45 (37.5%)

âœ… Data saved to:
   - CSV: data/topstartups_india_20251113_153045.csv
   - JSON: data/topstartups_india_20251113_153045.json
```

**Time**: 2-3 minutes (automated!)

---

## ðŸ“Š What Data You Get

Each startup includes:

| Field | Description | Example | Coverage |
|-------|-------------|---------|----------|
| **company_name** | Startup name | "Razorpay" | 100% |
| **hq_location** | Headquarters | "Bangalore, India" | 95% |
| **website_url** | Official website | "https://razorpay.com" | 80%+ |
| **website_available** | Has website? | True/False | 100% |
| **phone** | Contact number | "+91 80 6811 6000" | 40% |
| **employees** | Employee count | "501-1000" | 70% |
| **funding_amount** | Funding in $ | 375000000 ($375M) | 70% |
| **funding_raw** | Original text | "$375M" | 70% |
| **jobs_available** | Hiring status | True/False | 100% |
| **jobs_link** | Careers page | "razorpay.com/jobs" | 40% |
| **industry** | Category | "FinTech, Payments" | 85% |
| **founded_year** | Year started | 2014 | 60% |
| **description** | Company bio | "Payment gateway..." | 90% |

**Output files**:
- CSV: `data/topstartups_india_TIMESTAMP.csv`
- JSON: `data/topstartups_india_TIMESTAMP.json`

---

## ðŸŽ¯ Use Cases for Your Job Submission

### Use Case 1: Target Funded Startups

**Why**: Companies with funding = budget to buy your services!

```powershell
# After scraping, filter in Excel or Python:
python -c "
import pandas as pd
df = pd.read_csv('data/topstartups_india_*.csv')
funded = df[df['funding_amount'] > 1_000_000]  # >$1M funding
funded.to_csv('data/funded_startups.csv', index=False)
print(f'Found {len(funded)} funded startups!')
"
```

**Value**: Show you can target high-value clients (not just small businesses)

---

### Use Case 2: Find Hiring Companies

**Why**: Startups hiring = need marketing/recruitment/tech services NOW!

```python
import pandas as pd
df = pd.read_csv('data/topstartups_india_*.csv')
hiring = df[df['jobs_available'] == True]
hiring.to_csv('data/hiring_startups.csv', index=False)
```

**Value**: These are HOT LEADS ready to buy!

---

### Use Case 3: Segment by Industry

**Why**: Show you understand market segmentation!

```python
import pandas as pd
df = pd.read_csv('data/topstartups_india_*.csv')

# Group by industry
fintech = df[df['industry'].str.contains('FinTech', na=False)]
saas = df[df['industry'].str.contains('SaaS', na=False)]
ecommerce = df[df['industry'].str.contains('E-commerce', na=False)]

print(f"FinTech startups: {len(fintech)}")
print(f"SaaS startups: {len(saas)}")
print(f"E-commerce: {len(ecommerce)}")
```

**Value**: Professional segmentation impresses employers!

---

### Use Case 4: Find Companies Without Websites (URGENT)

**Why**: No website = immediate sales opportunity!

```python
df = pd.read_csv('data/topstartups_india_*.csv')
no_website = df[df['website_available'] == False]
no_website.to_csv('data/urgent_startup_leads.csv', index=False)
```

**Value**: These need web design/digital marketing services URGENTLY!

---

## ðŸ”§ Customization Options

### Option 1: Scrape Specific Categories

**Edit** `scrapers/topstartups_scraper.py` or use helper function:

```python
from scrapers.topstartups_scraper import scrape_by_category

# Scrape only AI startups
ai_startups = scrape_by_category('ai')
ai_startups.to_csv('data/ai_startups.csv', index=False)

# Scrape only FinTech
fintech = scrape_by_category('fintech')
```

**Popular categories**:
- `ai` - Artificial Intelligence
- `fintech` - Financial Technology
- `saas` - Software as a Service
- `ecommerce` - E-commerce
- `healthtech` - Healthcare Technology
- `edtech` - Education Technology

---

### Option 2: Scrape Specific Locations

```python
from scrapers.topstartups_scraper import scrape_by_location

# Bangalore startups only
bangalore = scrape_by_location('Bangalore')

# Mumbai startups
mumbai = scrape_by_location('Mumbai')

# Delhi NCR
delhi = scrape_by_location('Delhi')
```

---

### Option 3: Increase Scroll Count (More Companies)

**Edit line 310** in `topstartups_scraper.py`:

```python
# Default: 8 scrolls (~120 companies)
companies = scraper.scrape(scroll_times=8)

# More scrolls = more companies:
companies = scraper.scrape(scroll_times=15)  # ~200-250 companies
```

**Note**: More scrolls = slower (15 scrolls = 4-5 minutes)

---

### Option 4: Disable Headless Mode (See Browser)

**Edit line 309**:

```python
# See browser in action:
scraper = TopStartupsScr(headless=False)
```

**Use case**: Debugging or watching scraper work

---

## ðŸ’¡ Pro Tips

### Tip 1: Combine with Other Scrapers

**3-source strategy for maximum impact**:

```powershell
# Day 1 Morning:
python scrapers/google_maps_premium.py    # 150 businesses (verified)
python scrapers/topstartups_scraper.py     # 120 startups (funded)
python scrapers/indiamart_scraper.py       # 50 B2B (high email)

# Total: 320 businesses with DIVERSE DATA!
```

**Value**:
- Google Maps: Verified, high website coverage
- Top Startups: Funding data, hiring status
- IndiaMART: High email coverage

**This diversity shows strategic thinking!** ðŸ§ 

---

### Tip 2: Highlight Funding Data in Your Submission

**Example executive summary line**:
```
"Includes 87 funded startups with total funding of $2.3B, 
demonstrating ability to target high-value enterprise clients"
```

**This is UNIQUE data** your competitors won't have! ðŸ’Ž

---

### Tip 3: Use Job Listings as Intent Signal

**In your report**:
```
"45 startups currently hiring (37.5% of dataset), 
indicating immediate need for recruitment marketing, 
employer branding, and talent acquisition services"
```

**Shows you understand buyer intent!** ðŸŽ¯

---

### Tip 4: Cross-Reference with Other Data

**Enrich your data**:

```python
import pandas as pd

# Load all sources
google_maps = pd.read_csv('data/google_maps_premium_*.csv')
startups = pd.read_csv('data/topstartups_india_*.csv')

# Merge on company name
merged = pd.merge(google_maps, startups, 
                  left_on='name', right_on='company_name', 
                  how='outer')

# Now you have: phone from Google + funding from TopStartups!
merged.to_csv('data/enriched_startups.csv', index=False)
```

**Value**: Multi-source verification = higher quality!

---

## ðŸ“ˆ Expected Results

### Typical Scrape (8 scrolls, 3 minutes):

```
Total Companies: 120
Website Coverage: 80-85% (96-102 companies)
Phone Coverage: 35-45% (42-54 companies)
Funding Info: 70-75% (84-90 companies)
Jobs Available: 35-40% (42-48 companies)
Employee Data: 65-75% (78-90 companies)
```

**Quality score**: â­â­â­â­â­ (5/5)

**Why it's valuable**:
- Funding data = can afford your services
- Hiring = immediate need
- Employees = company size (qualify leads)
- Verified startups = real businesses

---

### Large Scrape (15 scrolls, 5 minutes):

```
Total Companies: 200-250
Website Coverage: 80%+ (160-200 companies)
Funding Info: 70%+ (140-175 companies)
Total Funding: $5B-$10B+ (impressive!)
```

**Use case**: Build comprehensive startup database

---

## ðŸš¨ Troubleshooting

### Error: "Chrome WebDriver not found"

**Fix**: Install ChromeDriver

```powershell
# Option 1: Auto-install (recommended)
pip install webdriver-manager

# Then edit line 45 in topstartups_scraper.py:
from webdriver_manager.chrome import ChromeDriverManager
self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
```

**Option 2**: Download manually from https://chromedriver.chromium.org/

---

### Error: "No company blocks found"

**Fix**: Website structure may have changed

1. Set `headless=False` to see the page
2. Check if page loads correctly
3. Try increasing scroll count: `scroll_times=12`
4. Check your internet connection

---

### Low Phone Coverage (~40%)

**This is normal!** Startups often don't list phone numbers publicly.

**Solutions**:
- Cross-reference with Google Maps (better phone coverage)
- Use email instead (if available)
- Visit website's contact page manually

---

### Scraper is Slow (5+ minutes)

**This is expected** - dynamic content takes time.

**Speed tips**:
- Reduce scroll count: `scroll_times=5` (fewer companies)
- Use headless mode (default)
- Close other browser tabs
- Check internet speed

---

## ðŸŽ¯ Integration with Your Workflow

### Step 1: Scrape Startups (Day 1)

```powershell
python scrapers/topstartups_scraper.py
```

**Output**: `data/topstartups_india_TIMESTAMP.csv`

---

### Step 2: Filter High-Value Leads (Day 2)

```python
import pandas as pd
df = pd.read_csv('data/topstartups_india_*.csv')

# Filter: Funded + Hiring + Bangalore
high_value = df[
    (df['funding_amount'] > 5_000_000) &  # >$5M funding
    (df['jobs_available'] == True) &       # Hiring
    (df['hq_location'].str.contains('Bangalore', na=False))
]

high_value.to_csv('data/high_value_startups.csv', index=False)
print(f"Found {len(high_value)} high-value leads!")
```

---

### Step 3: Merge with Other Sources (Day 3)

```powershell
# Combine all scraped data
python -c "
import pandas as pd
import glob

files = glob.glob('data/*.csv')
df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
df.drop_duplicates(subset=['company_name', 'phone'], inplace=True)
df.to_csv('data/FINAL_500_leads.csv', index=False)
print(f'Merged {len(df)} unique businesses')
"
```

---

### Step 4: Analyze for Submission (Day 3)

**Create insights**:

```python
df = pd.read_csv('data/FINAL_500_leads.csv')

print("="*50)
print("SUBMISSION HIGHLIGHTS")
print("="*50)
print(f"Total Businesses: {len(df)}")
print(f"Total Funding (startups): ${df['funding_amount'].sum():,.0f}")
print(f"Companies Hiring: {df['jobs_available'].sum()}")
print(f"Website Coverage: {df['website_available'].sum() / len(df) * 100:.1f}%")
print("="*50)
```

**Include this in your executive summary!**

---

## âœ… Pre-Flight Checklist

Before running the scraper:

- [ ] Python installed
- [ ] Chrome browser installed
- [ ] selenium library installed (`pip install selenium`)
- [ ] beautifulsoup4 + lxml installed
- [ ] pandas installed
- [ ] Internet connection active
- [ ] 5 minutes available (scraping time)

**If all checked** â†’ **RUN IT!** ðŸš€

---

## ðŸ“Š Sample Output Preview

**CSV Preview** (`topstartups_india_TIMESTAMP.csv`):

```csv
company_name,hq_location,website_url,phone,employees,funding_amount,funding_raw,jobs_available,industry,founded_year
Razorpay,Bangalore India,https://razorpay.com,,501-1000,375000000,$375M,True,FinTech,2014
CRED,Bangalore India,https://cred.club,,201-500,215000000,$215M,True,FinTech,2018
Zerodha,Bangalore India,https://zerodha.com,,1001-5000,0,,False,FinTech,2010
Meesho,Bangalore India,https://meesho.com,,1001-5000,570000000,$570M,True,E-commerce,2015
```

**Key insights**:
- âœ… Funding amounts in dollars (easy to analyze)
- âœ… Employee ranges (company size)
- âœ… Job availability (intent signal)
- âœ… Website URLs (for enrichment)

---

## ðŸŽŠ You're Ready!

**What you have**:
- âœ… Professional startup scraper
- âœ… Modular and reusable code
- âœ… Rich data (funding, jobs, employees)
- âœ… Multiple output formats (CSV, JSON)
- âœ… Statistical analysis built-in

**What you can do**:
1. Scrape 100-250 Indian startups in 3 minutes
2. Filter by funding, hiring status, location
3. Segment by industry (FinTech, SaaS, AI, etc.)
4. Combine with Google Maps + IndiaMART data
5. Create impressive, multi-dimensional dataset

**Competitive advantage**:
- Your submission: 500 businesses + funding data + hiring status
- Typical submission: 500 businesses (basic info only)

**You'll stand out by 3x!** ðŸ†

---

## ðŸ“ž Quick Reference

**Run scraper**:
```powershell
python scrapers/topstartups_scraper.py
```

**Filter funded startups** (Python):
```python
import pandas as pd
df = pd.read_csv('data/topstartups_india_*.csv')
funded = df[df['funding_amount'] > 1_000_000]
funded.to_csv('data/funded_startups.csv', index=False)
```

**Filter hiring startups**:
```python
hiring = df[df['jobs_available'] == True]
hiring.to_csv('data/hiring_startups.csv', index=False)
```

**Scrape specific category**:
```python
from scrapers.topstartups_scraper import scrape_by_category
ai_df = scrape_by_category('ai')
```

---

**Happy scraping!** ðŸš€

**This scraper will help you stand out!** ðŸ’Ž
